{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "C192SOmJS6lw",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# CS 195: Natural Language Processing\n",
    "## Introduction to the Hugging Face Transformers Library\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/s26-CS195NLP/blob/main/F1_1_HuggingFace.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## References\n",
    "\n",
    "Hugging Face *Quicktour*: https://huggingface.co/docs/transformers/quicktour\n",
    "\n",
    "Hugging Face *Run Inference with Pipelines tutorial*: https://huggingface.co/docs/transformers/pipeline_tutorial\n",
    "\n",
    "Hugging Face *NLP Course, Chapter 2*: https://huggingface.co/learn/nlp-course/chapter2/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The Plan\n",
    "\n",
    "The first thing we're going to do is get comfortable with the Hugging Face *Transformers* library for Python\n",
    "\n",
    "Eventual goals:\n",
    "* understand and explain how transformer models work\n",
    "* create and adapt transformers for a specific purpose\n",
    "\n",
    "For now:\n",
    "* learn to *use* existing transformer models\n",
    "* understand *what* they can do\n",
    "* get a feel for pupular families of models and how they're related\n",
    "\n",
    "We will dig into the internals later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Hugging Face?\n",
    "\n",
    "Hugging Face is a private company\n",
    "* Founded in 2016 by French entrepreneurs Cl√©ment Delangue, Julien Chaumond, and Thomas Wolf\n",
    "* Based in New York City\n",
    "\n",
    "Provide a popular free, open-source Python library called **transformers** for NLP (and other) tasks\n",
    "\n",
    "Host *hundreds of thousands of models* that you can use in your own programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing the transformers module\n",
    "\n",
    "This is my favored way of installing packages from a Jupyter Notebook\n",
    "\n",
    "If you have lots of Python distributions installed, it should use the right one\n",
    "\n",
    "It may take a few minutes, but *you should only have to do this once*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/000794593/Library/Python/3.12/lib/python/site-packages (4.57.6)\n",
      "Requirement already satisfied: accelerate in /Users/000794593/Library/Python/3.12/lib/python/site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2026.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: psutil in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from accelerate) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from torch>=2.0.0->accelerate) (69.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/000794593/Library/Python/3.12/lib/python/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Using the sentiment analysis pipeline\n",
    "\n",
    "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
    "\n",
    "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
    "\n",
    "A **pipeline** is a series of steps for performing **inference**\n",
    "* tokenize and preprocess the input text (more on this later)\n",
    "* ask the model for a prediction\n",
    "* post-process model's result and turn it into something you can use\n",
    "\n",
    "![full_nlp_pipeline.svg](images/full_nlp_pipeline.svg)\n",
    "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We *are* specifying the kind of task: `sentiment-analysis`\n",
    "\n",
    "We *are not* asking for a specific model, so it picks one of many it has by default\n",
    "\n",
    "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984305500984192}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "classifier(\"I love how easy it is to build sentiment-aware applications with the transformers library!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Test it out:** Try changing the input to get different labels/scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Hardware Acceleration\n",
    "\n",
    "NLP Models are often *computationally intensive*\n",
    "\n",
    "Algorithms can be sped up using special hardware like\n",
    "* Graphics Processing Unit (GPU)\n",
    "* Tensor Processing Unit (TPU)\n",
    "* Other specialized devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "print(accelerator.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Here's how you can tell the pipeline to use acceleration.\n",
    "\n",
    "Examples from the Hugging Face documentation will often look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984305500984192}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from accelerate import Accelerator\n",
    "\n",
    "device = Accelerator().device\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\",device=device)\n",
    "\n",
    "classifier(\"I love how easy it is to build sentiment-aware applications with the transformers library!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Working with batches of text\n",
    "\n",
    "To get classifications of many different examples, pass in a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9991173148155212}, {'label': 'NEGATIVE', 'score': 0.9557347297668457}, {'label': 'NEGATIVE', 'score': 0.9962737560272217}]\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"It's really cool that you can get classifications for a whole batch of text\",\n",
    "                      \"I wonder if the rest of the class will be this easy.\",\n",
    "                     \"Spolier alert: it won't be.\"])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Note that the results come back as a list of dictionaries, so you can manipulate it in the normal ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence had POSITIVE sentiment, with a score of 0.9991173148155212\n"
     ]
    }
   ],
   "source": [
    "print(\"The sentence had\",results[0][\"label\"],\"sentiment, with a score of\",results[0][\"score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise: Specifying a model\n",
    "\n",
    "Now try asking for a specific model. \n",
    "\n",
    "Replace one line of code in your earlier example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "How is this model different from the first model? \n",
    "\n",
    "Create a cell in this notebook and note the differences you see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Applied Exploration\n",
    "\n",
    "The `roberta-base-go_emotions` model is documented here: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
    "\n",
    "Answer some questions about this:\n",
    "* What is `roberta-base`? Write down some things you can learn about it from the documentation.\n",
    "* What is `go_emotions`? Write down some things you can learn about it from the documentation.\n",
    "\n",
    "Go to the Hugging Face models page: https://huggingface.co/models\n",
    "* click `Text Classification`\n",
    "* Try some additional models\n",
    "    - test out at least one more sentiment/emotions model\n",
    "    - test out at least two other kinds of models - like news topic classification or spam detection\n",
    "    - write down some info about the models you found\n",
    "        - what is it for?\n",
    "        - who made it?\n",
    "        - what kind of data was it trained on?\n",
    "        - are they based on some other model and trained on new data (*fine-tuned*) for a specific task?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOf2oi4GbgdvkO0orSdgZtQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
